{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de52178a-e0d7-4a90-bbf6-fa52becf53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fccfd5e-64af-45cd-9a0f-c6f5840d53ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 courses. Processing...\n",
      "Processing course: Test (ID: 66e28db3e03af0d0f22e0ecd)\n",
      "Downloaded: studynotiondata\\66e28db3e03af0d0f22e0ecd_Test\\videos\\66e28db3e03af0d0f22e0ecd_x_clone.mp4\n",
      "Downloaded: studynotiondata\\66e28db3e03af0d0f22e0ecd_Test\\pdfs\\66e28db3e03af0d0f22e0ecd_Internshala_web_development_course_certificate.pdf\n",
      "Saved course description: studynotiondata\\66e28db3e03af0d0f22e0ecd_Test\\66e28db3e03af0d0f22e0ecd_description.txt\n",
      "Finished processing course: Test (ID: 66e28db3e03af0d0f22e0ecd)\n",
      "Processing course: Artificial_Intelligence__Machine_Learning_in_Finance_ (ID: 66e3ca71fec7d8a2197d52e3)\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Objective_.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Intro-1.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Intro-2.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Intro-3.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Data_Sources.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Data_Preprocessing.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Data_Generation.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Simple_Linear_Regression-1.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Simple_Linear_Regression-2.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Multiple_Linear_Regression-1.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\videos\\66e3ca71fec7d8a2197d52e3_Multiple_Linear_Regression-2.mp4\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_artificial_intelligence_in_finance.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_AIML.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_AIML_1.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_Introduction_to_ML.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_ML_.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_Supervised_learning_in_ML.pdf\n",
      "Downloaded: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\pdfs\\66e3ca71fec7d8a2197d52e3_Unsupervised_learning_in_ML.pdf\n",
      "Saved course description: studynotiondata\\66e3ca71fec7d8a2197d52e3_Artificial_Intelligence__Machine_Learning_in_Finance_\\66e3ca71fec7d8a2197d52e3_description.txt\n",
      "Finished processing course: Artificial_Intelligence__Machine_Learning_in_Finance_ (ID: 66e3ca71fec7d8a2197d52e3)\n",
      "Processing course: _Machine_Learning_Basics (ID: 66e4189d7f1beb57e8423402)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'studynotiondata\\\\66e4189d7f1beb57e8423402__Machine_Learning_Basics\\\\66e4189d7f1beb57e8423402_description.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch data from API. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(courses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m courses. Processing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m courses:\n\u001b[1;32m---> 67\u001b[0m         \u001b[43mprocess_course\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcourse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll courses processed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m, in \u001b[0;36mprocess_course\u001b[1;34m(course)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description:\n\u001b[0;32m     47\u001b[0m     description_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(course_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcourse_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_description.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdescription_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     49\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(description)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved course description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'studynotiondata\\\\66e4189d7f1beb57e8423402__Machine_Learning_Basics\\\\66e4189d7f1beb57e8423402_description.txt'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove invalid characters and replace spaces with underscores\n",
    "    return re.sub(r'[<>:\"/\\\\|?*&]', '', filename).replace(' ', '_')\n",
    "\n",
    "def download_file(url, folder, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        file_path = os.path.join(folder, sanitize_filename(filename))\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")\n",
    "\n",
    "def process_subsection(subsection, course_folder, course_id):\n",
    "    if 'pdfUrl' in subsection:\n",
    "        pdf_url = subsection['pdfUrl']\n",
    "        pdf_filename = f\"{course_id}_{subsection.get('fileName', os.path.basename(urlparse(pdf_url).path))}\"\n",
    "        download_file(pdf_url, os.path.join(course_folder, 'pdfs'), pdf_filename)\n",
    "    \n",
    "    if 'videoUrl' in subsection:\n",
    "        video_url = subsection['videoUrl']\n",
    "        video_filename = f\"{course_id}_{subsection.get('title', 'video')}.mp4\"\n",
    "        download_file(video_url, os.path.join(course_folder, 'videos'), video_filename)\n",
    "\n",
    "def process_course(course):\n",
    "    course_id = course['_id']\n",
    "    course_name = sanitize_filename(course['courseName'])\n",
    "    course_folder = os.path.join('studynotiondata', f\"{course_id}_{course_name}\")\n",
    "    \n",
    "    print(f\"Processing course: {course_name} (ID: {course_id})\")\n",
    "    \n",
    "    for section in course.get('courseContent', []):\n",
    "        for subsection in section.get('subSection', []):\n",
    "            process_subsection(subsection, course_folder, course_id)\n",
    "    \n",
    "    # Extract course description\n",
    "    description = course.get('courseDescription', '')\n",
    "    if description:\n",
    "        description_file = os.path.join(course_folder, f\"{course_id}_description.txt\")\n",
    "        with open(description_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(description)\n",
    "        print(f\"Saved course description: {description_file}\")\n",
    "    \n",
    "    print(f\"Finished processing course: {course_name} (ID: {course_id})\")\n",
    "\n",
    "def main():\n",
    "    url = \"https://studynotion-backend-z1s7.onrender.com/api/v1/course/getAllCoursesPopulated\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        courses = data.get('data', [])\n",
    "        \n",
    "        os.makedirs('studynotiondata', exist_ok=True)\n",
    "        \n",
    "        print(f\"Found {len(courses)} courses. Processing...\")\n",
    "        \n",
    "        for course in courses:\n",
    "            process_course(course)\n",
    "        \n",
    "        print(\"All courses processed successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from API. Status code: {response.status_code}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bbbe59-9273-4534-801a-583f00add5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 66e28db3e03af0d0f22e0ecd: 100%|███████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Processing 66e3ca71fec7d8a2197d52e3: 100%|███████████████████████████████████████████████| 7/7 [00:19<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import cohere\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Cohere and Pinecone clients\n",
    "cohere_api_key = \"OVQ8g0SvIGz59Jxyuj2YKPKmrV17IqvxPpUlxL23\"\n",
    "pinecone_api_key = \"b1492bce-247e-46d9-b61e-25a4abe015ca\"\n",
    "pinecone_environment = \"us-east-1\"\n",
    "pinecone_index_name = \"studynotion-project\"\n",
    "\n",
    "\n",
    "co = cohere.Client(cohere_api_key)\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Function to get embedding dimension\n",
    "def get_embedding_dimension(text):\n",
    "    response = co.embed(\n",
    "        texts=[text],\n",
    "        model=\"embed-english-v3.0\",\n",
    "        input_type=\"search_document\"\n",
    "    )\n",
    "    return len(response.embeddings[0])\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def process_course_folder(course_folder):\n",
    "    pdf_folder = os.path.join(course_folder, 'pdfs')\n",
    "    if not os.path.exists(pdf_folder):\n",
    "        print(f\"No PDF folder found in {course_folder}\")\n",
    "        return\n",
    "\n",
    "    course_texts = []\n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            course_texts.append((pdf_file, text))\n",
    "    \n",
    "    return course_texts\n",
    "\n",
    "def embed_and_store(course_id, course_texts):\n",
    "    # Get the embedding dimension\n",
    "    sample_text = course_texts[0][1] if course_texts else \"Sample text\"\n",
    "    embedding_dim = get_embedding_dimension(sample_text)\n",
    "\n",
    "    # Check if the index exists, if not create it\n",
    "    if pinecone_index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=pinecone_index_name,\n",
    "            dimension=embedding_dim,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region=pinecone_environment\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Connect to the index\n",
    "    index = pc.Index(pinecone_index_name)\n",
    "\n",
    "    # Check if the index dimension matches the embedding dimension\n",
    "    index_stats = index.describe_index_stats()\n",
    "    if index_stats['dimension'] != embedding_dim:\n",
    "        raise ValueError(f\"Index dimension ({index_stats['dimension']}) does not match embedding dimension ({embedding_dim})\")\n",
    "\n",
    "    for pdf_name, text in tqdm(course_texts, desc=f\"Processing {course_id}\"):\n",
    "        # Generate embeddings\n",
    "        response = co.embed(\n",
    "            texts=[text],\n",
    "            model=\"embed-english-v3.0\",\n",
    "            input_type=\"search_document\"\n",
    "        )\n",
    "        embedding = response.embeddings[0]\n",
    "\n",
    "        # Store in Pinecone\n",
    "        try:\n",
    "            index.upsert(vectors=[\n",
    "                (f\"{course_id}_{pdf_name}\", embedding, {\"text\": text[:1000]})  # Truncate text if needed\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"Error upserting vector for {pdf_name}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    base_folder = 'studynotiondata'\n",
    "    for course_folder in os.listdir(base_folder):\n",
    "        course_path = os.path.join(base_folder, course_folder)\n",
    "        if os.path.isdir(course_path):\n",
    "            course_id = course_folder.split('_')[0]\n",
    "            course_texts = process_course_folder(course_path)\n",
    "            if course_texts:\n",
    "                embed_and_store(course_id, course_texts)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd31f55d-0eef-48e9-b001-057a1b113b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.19, Text:  \n",
      "   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "   \n",
      "Artificial intelligence and machine learning in financial services  \n",
      "Market developments and financial stability implications  \n",
      " \n",
      "        \n",
      "1 November  2017  \n",
      " \n",
      " \n",
      "  \n",
      "  \n",
      " \n",
      "                \n",
      " \n",
      "The Financial Stability Board (FSB) is established to coordinate at the international level the \n",
      "work of national financial authorities and international standard -setting bodies in order to \n",
      "develop and promote the implementation of effective regulatory, sup ervisory and other \n",
      "financial sector policies. Its mandate is set out in the FSB Charter, which governs the policymaking and related activities of the FSB. These activities, including any decisions reached in their context, shall not be binding or give rise  to any legal rights or obligations under \n",
      "the FSB’s Articles of Association.  \n",
      " \n",
      " \n",
      "Contacting the Financial Stability Board  \n",
      "Sign up for e -mail alerts: www.fsb.org/emailalert  \n",
      "Follow the FSB on Twitter: @FinStbBoard  \n",
      "E-mail the FSB at: fsb@fsb.org  \n",
      " \n",
      "Score: 0.19, Text: Artificial \n",
      "intelligence \n",
      "in finance\n",
      "Bonnie G. Buchanan, PhD, FRSAhttps://doi.org/ 10.5281/zenodo.2612537\n",
      "This  wor k was supported by  The Al an Turing Institute \n",
      "under  the EPSRC  grant E P/N510129/1  \n",
      "Artificial intelligence in finance \n",
      "April 201 9 \n",
      "Bonnie G . Buchan an, PhD, FRSA  \n",
      "Howar d Bosanko Professor o f Eco nomics a nd Finance \n",
      "Department o f Finance , \n",
      "Albers S chool o f Business a nd Economics \n",
      "Seattle  University \n",
      "Seattle, W ashington 98122 -1090 \n",
      "Email : buchanab@seattleu.edu  \n",
      "Ph: (20 6) 296- 5977 \n",
      "Hanken School o f Economics \n",
      "Department of Finance, S tatistics a nd Economics \n",
      "P.O. Box 4 79, FI -00101 Helsinki, Finland \n",
      "Abstract \n",
      "Artificial intelligence (AI) is rapidly  transforming the global financial services industry. As a group of \n",
      "related technologies  that include machine learning (ML) and deep learning (DL) , AI has  the potential \n",
      "to disrupt and refine  the existing financial services industry. I review the extant academic, practitioner \n",
      "and policy related AI \n",
      "Score: 0.16, Text:  \n",
      " \n",
      "  \n",
      " Artificial Intelligence and Machine Learning \n",
      "in Financial Services  \n",
      "April 3, 2024  \n",
      "Congressional Research Service  \n",
      "https://crsreports.congress.gov  \n",
      "R47997   \n",
      "Congressional Research Service   \n",
      "SUMMARY  \n",
      " \n",
      "Artificial Intelligence and Machine Learning in \n",
      "Financial Services  \n",
      "The financial industry’s adoption of artificial intelligence  (AI) and machine  learning (ML) is \n",
      "evolving as financial firms employ ever greater levels of  technology and automation to deliver \n",
      "services . Expand ing on earlier models of quantitative analysis , AI/ML  has often been adopted in \n",
      "finance to solve  discrete challenges , such as maximizing profit and minimizing risk. Yet the \n",
      "industry’s adoption of the newer technology also occurs against perceptions  that are steeped in \n",
      "tradition  and historical financial regulation , and regulators want to ensure that th e technology \n",
      "does not sideste p regulations frequently described as technology neutral.  \n",
      "Technological advances in computer hardware, \n",
      "Score: 0.09, Text: 2]]\n",
      "SUPER VISED\n",
      "LEARNING\n",
      "Supervised\n",
      "learning\n",
      "is\n",
      "a\n",
      "type\n",
      "of\n",
      "machine\n",
      "learning\n",
      "where\n",
      "a\n",
      "model\n",
      "is\n",
      "trained\n",
      "on\n",
      "labeled\n",
      "data.\n",
      "This\n",
      "means\n",
      "the\n",
      "algorithm\n",
      "is\n",
      "provided\n",
      "with\n",
      "input-output\n",
      "pairs,\n",
      "and\n",
      "the\n",
      "goal\n",
      "is\n",
      "to\n",
      "learn\n",
      "a\n",
      "function\n",
      "that\n",
      "maps\n",
      "inputs\n",
      "to\n",
      "desired\n",
      "outputs.\n",
      "Supervised\n",
      "learning\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "commonly\n",
      "used\n",
      "techniques\n",
      "in\n",
      "machine\n",
      "learning\n",
      "because\n",
      "it\n",
      "is\n",
      "straightforward\n",
      "and\n",
      "effective\n",
      "for\n",
      "a\n",
      "wide\n",
      "range\n",
      "of\n",
      "problems,\n",
      "such\n",
      "as\n",
      "classification\n",
      "and\n",
      "regression.\n",
      "#\n",
      "Key\n",
      "Concepts\n",
      "in\n",
      "Supervised\n",
      "Learning\n",
      "1.\n",
      "**Labeled\n",
      "Data**:\n",
      "In\n",
      "supervised\n",
      "learning,\n",
      "the\n",
      "training\n",
      "data\n",
      "consists\n",
      "of\n",
      "input-output\n",
      "pairs.\n",
      "Each\n",
      "input\n",
      "is\n",
      "associated\n",
      "with\n",
      "a\n",
      "corresponding\n",
      "label\n",
      "or\n",
      "target\n",
      "value.\n",
      "For\n",
      "example,\n",
      "in\n",
      "a\n",
      "spam\n",
      "detection\n",
      "problem,\n",
      "the\n",
      "input\n",
      "could\n",
      "be\n",
      "an\n",
      "email,\n",
      "and\n",
      "the\n",
      "label\n",
      "could\n",
      "be\n",
      "\"spam\"\n",
      "or\n",
      "\"not\n",
      "spam.\"\n",
      "2.\n",
      "**Training\n",
      "and\n",
      "Test\n",
      "Sets**:\n",
      "The\n",
      "dataset\n",
      "is\n",
      "usually\n",
      "divided\n",
      "into\n",
      "two\n",
      "subsets:\n",
      "a\n",
      "training\n",
      "set\n",
      "and\n",
      "a\n",
      "test\n",
      "set.\n",
      "The\n",
      "model\n",
      "is\n",
      "trained\n",
      "on\n",
      "the\n",
      "training\n",
      "set\n",
      "and\n",
      "evaluated\n",
      "on\n",
      "the\n",
      "test\n",
      "set\n",
      "to\n",
      "measure\n",
      "its\n",
      "performance.\n",
      "3.\n",
      "**Learning\n",
      "Objective\n",
      "Score: 0.07, Text: 1]]Detailed\n",
      "Overview\n",
      "of\n",
      "Machine\n",
      "Learning\n",
      "1.\n",
      "Definition\n",
      "and\n",
      "Core\n",
      "Concepts\n",
      "Machine\n",
      "learning\n",
      "(ML)\n",
      "is\n",
      "a\n",
      "subset\n",
      "of\n",
      "artificial\n",
      "intelligence\n",
      "that\n",
      "focuses\n",
      "on\n",
      "creating\n",
      "systems\n",
      "that\n",
      "can\n",
      "learn\n",
      "and\n",
      "improve\n",
      "from\n",
      "experience\n",
      "without\n",
      "explicit\n",
      "programming.\n",
      "The\n",
      "core\n",
      "idea\n",
      "is\n",
      "to\n",
      "develop\n",
      "algorithms\n",
      "that\n",
      "can\n",
      "automatically\n",
      "identify\n",
      "patterns\n",
      "in\n",
      "data\n",
      "and\n",
      "use\n",
      "these\n",
      "patterns\n",
      "to\n",
      "make\n",
      "predictions\n",
      "or\n",
      "decisions.\n",
      "Key\n",
      "concepts\n",
      "in\n",
      "machine\n",
      "learning\n",
      "include:\n",
      "-\n",
      "**Data**:\n",
      "The\n",
      "foundation\n",
      "of\n",
      "any\n",
      "ML\n",
      "system.\n",
      "This\n",
      "can\n",
      "be\n",
      "structured\n",
      "(like\n",
      "databases)\n",
      "or\n",
      "unstructured\n",
      "(like\n",
      "text\n",
      "or\n",
      "images).\n",
      "-\n",
      "**Features**:\n",
      "The\n",
      "individual\n",
      "measurable\n",
      "properties\n",
      "of\n",
      "the\n",
      "phenomena\n",
      "being\n",
      "observed.\n",
      "-\n",
      "**Models**:\n",
      "Mathematical\n",
      "representations\n",
      "of\n",
      "real-world\n",
      "processes.\n",
      "-\n",
      "**Training**:\n",
      "The\n",
      "process\n",
      "of\n",
      "teaching\n",
      "a\n",
      "model\n",
      "to\n",
      "make\n",
      "predictions\n",
      "using\n",
      "data.\n",
      "-\n",
      "**Inference**:\n",
      "Using\n",
      "a\n",
      "trained\n",
      "model\n",
      "to\n",
      "make\n",
      "predictions\n",
      "on\n",
      "new,\n",
      "unseen\n",
      "data.\n",
      "2.\n",
      "Types\n",
      "of\n",
      "Machine\n",
      "Learning\n",
      "2.1\n",
      "Supervised\n",
      "Learning\n",
      "In\n",
      "supervised\n",
      "learning,\n",
      "the\n",
      "algorithm\n",
      "learns\n",
      "from\n",
      "labeled\n",
      "data.\n",
      "It's\n",
      "given\n",
      "both\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import pinecone\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Cohere client\n",
    "co = cohere.Client('OVQ8g0SvIGz59Jxyuj2YKPKmrV17IqvxPpUlxL23')  # Replace with your Cohere API key\n",
    "\n",
    "# Initialize the Pinecone client\n",
    "pc = pinecone.Pinecone(api_key='b1492bce-247e-46d9-b61e-25a4abe015ca', environment='us-east-1')  # Replace with your Pinecone API key\n",
    "\n",
    "# Connect to your Pinecone index\n",
    "index_name = 'studynotion-project'  # Replace with your Pinecone index name\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "def get_query_embedding(query):\n",
    "    # Generate the embedding for the query\n",
    "    response = co.embed(\n",
    "        texts=[query],\n",
    "        model='embed-english-v3.0',\n",
    "        input_type='search_query',\n",
    "        truncate='END'\n",
    "    )\n",
    "    return response.embeddings[0]\n",
    "\n",
    "def query_pinecone(query, top_k=5):\n",
    "    # Get the embedding for the query\n",
    "    embedding = get_query_embedding(query)\n",
    "    \n",
    "    # Query the Pinecone index\n",
    "    response = index.query(vector=embedding, top_k=top_k, include_metadata=True)\n",
    "    \n",
    "    # Return the results\n",
    "    return response['matches']\n",
    "\n",
    "# The input query\n",
    "query = \"What caused the 1929 Great Depression?\"\n",
    "\n",
    "# Fetch similar data from Pinecone\n",
    "matches = query_pinecone(query)\n",
    "\n",
    "# Print the results\n",
    "for match in matches:\n",
    "    print(f\"Score: {match['score']:.2f}, Text: {match['metadata']['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b8f48-b068-4829-a474-724cfbab65b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
